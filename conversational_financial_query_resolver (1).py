# -*- coding: utf-8 -*-
"""Conversational Financial Query Resolver.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16_OXInPMT54ocBbFNlHMavV9lbxRd3gg
"""

!pip install crewAI pandas matplotlib pandas matplotlib pyngrok

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import sqlite3
from crewai import Agent, Task, Crew
import os
import re
import json
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.gridspec import GridSpec

# Initialize database and environment
conn = sqlite3.connect(':memory:')
cursor = conn.cursor()
os.environ["OPENAI_API_KEY"] = "api-key"
openai_key = os.getenv("OPENAI_API_KEY")
count = 0
max_refinement_attempts = 10
refinement_feedback = {}

# Load data
df = pd.read_csv('/content/drive/My Drive/financial_agents/data/annual_balance and annual_revenue data.csv')
df['row_id'] = df.index.astype(str)

# Create table
cursor.execute('''
    CREATE TABLE financial_data (
        row_id TEXT PRIMARY KEY,
        year INTEGER,
        month INTEGER,
        section TEXT,
        description TEXT,
        value REAL,
        source_file TEXT
    )
''')

# Insert data
for _, row in df.iterrows():
    cursor.execute('''
        INSERT INTO financial_data (row_id, year, month, section, description, value, source_file)
        VALUES (?, ?, ?, ?, ?, ?, ?)
    ''', tuple(row[['row_id', 'year', 'month', 'section', 'description', 'value', 'source_file']]))

conn.commit()

# Available sections
available_sections = [
    'Income', 'Direct Expenses', 'Indirect Expenses', 'Depreciation', 'Profit',
    'Sources of Fund', 'Application of Fund', 'Free Cash', 'Other Financials', 'Finance Costs'
]

query = input("Enter your question here: ")

# Define agents with refinement feedback support
def create_agents(refinement_feedback=None):
    query_analyzer = Agent(
        role="Query Analyzer",
        goal="Analyze financial queries and generate a single SQL SELECT query to fetch raw data",
        backstory=(
            "You are a financial analyst and data strategist. Your task is to interpret natural language financial questions and generate SQL SELECT queries "
            "to extract raw data for metric computation. You never calculate, summarize, or aggregate. Instead, you retrieve detailed raw rows.\n\n"

            "You work with a table called `financial_data` that has the following columns:\n"
            "- year, month, section, description, value, source_file\n\n"

            "Query Requirements:\n"
            "- Your SQL SELECT query must include WHERE clauses to filter by `section` and `year` only.\n"
            "- **Do not filter by `description`** in the SQL. Just choose the correct `section` based on your understanding.\n"
            "- Use `year >= 2022` when the user says 'last 3 years'. Assume the current year is 2025.\n"
            "- Always add `ORDER BY year, month`.\n"
            "- Important: **Never return multiple SQL queries. Always combine all required sections into a single query using `section IN (...)`**.\n"
            "- This is because all financial data has already been merged into a single table across 6 source documents.\n\n"

            "You must always follow this step-by-step reasoning process **before** generating the SQL:\n\n"

            "**STEP 1: Understand the user's query**\n"
            "- What exactly is being asked?\n"
            "- Is it a simple data pull or a calculated metric?\n\n"

            "**STEP 2: If the query involves a metric, define the formula**\n"
            "- What is the financial formula to answer this question?\n"
            "- Example: Gross Profit Margin = (Revenue - COGS) / Revenue\n"
            "- Example: Inventory Turnover = COGS / Average Inventory\n\n"

            "**STEP 3: Identify raw data required to calculate the formula**\n"
            "- List each component of the formula and what it represents (e.g., revenue, COGS, inventory)\n\n"

            "**STEP 4: Map those components to financial `section(s)`**\n"
            "- Example: Revenue → 'Income', COGS → 'Direct Expenses', Inventory → 'Application of Fund'\n\n"

            "**STEP 5: Write one SQL SELECT query**\n"
            "- Use only the needed `section(s)` and filter by `year >= 2022`\n"
            "- Never perform the calculation — only return the raw rows\n\n"

            "Financial data is organized into two major groups:\n\n"

            "**Revenue Sheet Sections**:\n"
            "- **Income**: Revenue, rebates, capitalized work, other income\n"
            "- **Direct Expenses**: COGS, raw materials, freight, labor, utilities\n"
            "- **Indirect Expenses**: Salaries, admin, legal, travel\n"
            "- **Profit**: EBIT, EBITDA, Gross Profit, PAT, PBT\n"
            "- **Depreciation**: Asset amortization\n"
            "- **Finance Costs**: Interest, leasing interest\n\n"

            "**Balance Sheet Sections**:\n"
            "- **Sources of Fund**: Equity, retained earnings\n"
            "- **Application of Fund**: Inventory, cash, fixed assets, current assets\n"
            "- **Free Cash**: Cash flow, CapEx, working capital, taxes\n"
            "- **Other Financials**: Net debt, ratios, working capital\n\n"

            "**Final SQL structure must look like this:**\n"
            "```sql\n"
            "SELECT year, month, section, description, value, source_file\n"
            "FROM financial_data\n"
            "WHERE year >= 2022 AND section IN (...)\n"
            "ORDER BY year, month;\n"
            "```\n\n"

            "You are a financial reasoning engine. Always analyze the query deeply, define the logic or formula, identify what raw data is needed, and only then retrieve it — in one SQL query."
        ) + (f"\n\nPrevious attempt feedback: {refinement_feedback.get('query_analyzer', '')}" if refinement_feedback else ""),
        verbose=False,
        allow_delegation=True,
        model="gpt-4o"
    )

    cfo = Agent(
        role="CFO Analyst",
        goal="Perform detailed financial analysis with precise calculations based on query requirements",
        backstory=(
            "You are a highly intelligent virtual CFO responsible for interpreting structured financial data and delivering executive-grade insights.\n\n"
            "Your responsibilities:\n"
            "1. First understand the user's original query and the raw data fetched by the SQL query\n"
            "2. Identify the exact formula or calculation needed to answer the query\n"
            "3. Perform precise calculations on the raw data, showing your step-by-step work\n"
            "4. Organize data by relevant time periods (yearly, quarterly, monthly)\n"
            "5. Calculate growth rates, percentages, ratios, and year-over-year changes based on the users query what they want \n"
            "6. Explicitly show how each calculation is performed (e.g., '2023 Revenue:X, 2024 Revenue: Y, YoY Growth: (Y-X)/X = Z%')\n"
            "7. Provide business context for the numbers and highlight significant trends\n"
            "8. Format all monetary values consistently (e.g., '1,234,567')\n"
            "9. Structure your response with clear sections: Summary, Calculations, Insights, and Recommendations\n\n"
            "10. check which data fetched and what is the data sections like as follows for every section there are description you need to check for fetched data  :-"
            "Income: Revenue, rebates, capitalized work, other income\n"
            "- **Direct Expenses**: COGS, raw materials, freight, labor, utilities\n"
            "- **Indirect Expenses**: Salaries, admin, legal, travel\n"
            "- **Profit**: EBIT, EBITDA, Gross Profit, PAT, PBT\n"
            "- **Depreciation**: Asset amortization\n"
            "- **Finance Costs**: Interest, leasing interest\n\n"

            "When processing data from financial_data table:\n"
            "- Pay attention to both 'section' and 'description' fields to identify specific line items\n"
            "- Group data by year/month as needed for time-series analysis\n"
            "- For percentage changes, use the formula: ((current - previous) / previous) * 100\n"
            "- For compound metrics (like profit margins), combine data from multiple sections\n"
            "- Always validate calculations by cross-checking totals\n\n"

            "Your output must include:\n"
            "1. A clear restatement of what metric you're calculating based on the query\n"
            "2. The exact numerical results with proper formatting\n"
            "3. A table of raw and calculated values (if appropriate)\n"
            "4. Narrative insights explaining business implications\n"
            "5. The raw data structure you worked with (as a reference)"
        ) + (f"\n\nPrevious attempt feedback: {refinement_feedback.get('cfo', '')}" if refinement_feedback else ""),
        verbose=False,
        allow_delegation=False,
        model="gpt-4o"
    )

    chart_agent = Agent(
        role="Chart Strategist",
        goal="Create multiple optimal data visualizations with properly formatted data structures for plotting",
        backstory=(
            "You are a seasoned financial data visualization expert who creates chart-ready data structures.\n\n"
            "Your process:\n"
            "1. Carefully review the CFO's analysis and calculated metrics\n"
            "2. Determine the most appropriate visualization types for the specific financial metric\n"
            "3. Create multiple chart designs when appropriate (e.g., trend view and breakdown view)\n"
            "4. Create complete JSON structures that can be directly used for plotting, including:\n"
            "   - For time series: yearly/monthly data points properly ordered\n"
            "   - For comparisons: correctly paired categories and values\n"
            "   - For distributions: properly calculated percentages\n\n"

            "Chart selection principles:\n"
            "- Line charts: for continuous metrics over time (growth trends, cumulative values)\n"
            "- Bar charts: for comparing discrete values (yearly revenues, category comparisons)\n"
            "- Pie charts: for composition analysis (expense breakdown, revenue sources)\n"
            "- Tables: for precise numerical data that requires exact values\n"
            "- Combined charts: when multiple perspectives enhance understanding\n\n"

            "Your output must include an array of chart specifications, with each chart having:\n"
            "1. chart_type: The specific visualization type ('line', 'bar', 'pie', 'stacked_bar', etc.)\n"
            "2. chart_title: A descriptive, business-focused title\n"
            "3. data: A complete JSON structure with all values needed for plotting\n"
            "4. x_axis_label: Clear description of what the x-axis represents\n"
            "5. y_axis_label: Clear description of what the y-axis represents\n"
            "6. legend_items: Labels for each data series if multiple series exist\n"
            "7. annotations: Key points to highlight on the chart (if applicable)\n\n"

            "For different chart types, provide appropriate data structures:\n"
            "- Line/Bar charts: [{x: '2022', y: 1200000}, {x: '2023', y: 1500000}, ...]\n"
            "- Pie charts: [{name: 'Category A', value: 30}, {name: 'Category B', value: 70}, ...]\n"
            "- Stacked charts: Multiple series with consistent x values\n"
            "- Tables: Column definitions and row data\n\n"

            "Ensure all data is properly formatted, sorted chronologically for time series, and includes appropriate labels and titles.\n\n"

            "IMPORTANT: For most financial queries, create at least 2 different chart types that offer complementary views of the data. For example:\n"
            "1. A time series view showing trends over years\n"
            "2. A comparison view showing categorical breakdowns\n"

            "Your final output should be a JSON array containing multiple chart objects:\n"
            "```json\n"
            "[\n"
            "  {\n"
            "    \"chart_type\": \"line\",\n"
            "    \"chart_title\": \"Revenue Growth 2022-2025\",\n"
            "    \"data\": [{\"x\": \"2022\", \"y\": 1200000}, ...],\n"
            "    \"x_axis_label\": \"Year\",\n"
            "    \"y_axis_label\": \"Revenue ($)\"\n"
            "  },\n"
            "  {\n"
            "    \"chart_type\": \"pie\",\n"
            "    \"chart_title\": \"Revenue Breakdown by Category 2025\",\n"
            "    \"data\": [{\"name\": \"Product A\", \"value\": 45}, ...]\n"
            "  }\n"
            "]\n"
            "```"
        ) + (f"\n\nPrevious attempt feedback: {refinement_feedback.get('chart_agent', '')}" if refinement_feedback else ""),
        verbose=False,
        allow_delegation=False,
        model="gpt-4o"
    )

    quality_analysis = Agent(
        role="Quality Analyst",
        goal="Ensure data was fetched, calculations were completed, and chart data was generated",
        backstory=(
            "You are a financial data quality validator with three specific responsibilities:\n\n"

            "1. DATA FETCHING VALIDATION: Verify that data was successfully fetched.\n"
            "   - Check ONLY if any data was returned from the SQL query\n"
            "   - Ignore which sections were selected or query construction details\n"
            "   - Only check if data exists, not whether it's the right data\n\n"

            "2. CFO CALCULATION VALIDATION: Verify calculations were completed.\n"
            "   - Check ONLY if calculations were performed by the CFO\n"
            "   - Verify numerical results exist in the output\n"
            "   - Ignore the correctness or appropriateness of the calculations\n\n"

            "3. CHART DATA VALIDATION: Verify chart data was generated.\n"
            "   - Check ONLY if chart data structures were created\n"
            "   - Verify the presence of chart specifications in JSON format\n"
            "   - Ignore chart type selection or design details\n\n"

            "Your output must follow this exact structure:\n"
            "{\n"
            "  \"needs_refinement\": true/false,\n"
            "  \"feedback\": {\n"
            "    \"query_analyzer\": \"ONLY feedback about whether data was fetched\",\n"
            "    \"cfo\": \"ONLY feedback about whether calculations were performed\",\n"
            "    \"chart_agent\": \"ONLY feedback about whether chart data was generated\"\n"
            "  }\n"
            "}\n\n"

            "If any component needs refinement, set needs_refinement to true. Otherwise, set it to false."
        ),
        verbose=False,
        allow_delegation=False,
        model="gpt-4o"
    )

    return query_analyzer, cfo, chart_agent, quality_analysis

# Define task creation function
def create_tasks(query_analyzer, cfo, chart_agent, quality_analysis, query, sql_query=None, fetched_data=None):
    query_task = Task(
        description=f"""The user asked:
        "{query}"
        Generate a SQL SELECT query (no aggregation) using the following columns: year, month, section, description, value, source_file.
        Available sections: {', '.join(available_sections)}.""",
        expected_output="SQL query",
        agent=query_analyzer
    )

    cfo_task = Task(
        description=f"""
        Analyze the financial data returned by the query: "{query}"
        {f"Using SQL query: {sql_query}" if sql_query else ""}
        The data structure is a list of tuples, each representing a row with columns: year, month, section, description, value, source_file.

        Your task:
        1. Analyze from 2022 to the current year (2025)
        2. Process this raw data to answer the specific query
        3. Identify the formula or calculation needed (e.g., percentage change = (current - previous)/previous * 100)
        4. Perform all necessary calculations showing your work
        5. Group by relevant time periods (e.g., yearly)
        6. Calculate any required metrics (growth rates, percentages, etc.)
        7. Provide business context and highlight significant trends
        8. Format your response with clear sections: Summary, Calculations, Insights, and Recommendations
        9. Show all formulas and calculations

        The query is asking about: "{query}"
        """,
        expected_output="Financial insights with calculations",
        agent=cfo
    )

    chart_task = Task(
        description=f"""
        Create multiple visualizations based on the CFO agent response for the query: "{query}"

        Your task:
        1. Review the financial analysis and determine at least 2 appropriate chart types
        2. Create complete JSON data structures ready for plotting
        3. Ensure all data is properly formatted and sorted chronologically
        4. For each chart, include:
          - chart_type (e.g., 'line', 'bar', 'pie')
          - chart_title
          - data array with properly formatted values
          - axis labels when applicable

        Return an array of chart specifications in this format:
        [
          {{
            "chart_type": "line",
            "chart_title": "Revenue Growth 2022-2025",
            "data": [{{...}}, {{...}}],
            "x_axis_label": "Year",
            "y_axis_label": "Revenue ($)"
          }},
          {{
            "chart_type": "pie",
            "chart_title": "Revenue Breakdown 2025",
            "data": [{{...}}, {{...}}]
          }}
        ]

        Ensure each visualization addresses a different aspect of the query: "{query}"
        """,
        expected_output="Multiple chart visualization specifications",
        agent=chart_agent
    )

    quality_task = Task(
        description=f"""
        Evaluate all outputs to ensure they effectively address the user's query: "{query}"

        Evaluate these outputs STRICTLY based on these criteria ONLY:

        1. DATA FETCHING - Check ONLY if:
           - Data was successfully fetched from the database (any rows returned)
           - Do NOT check which sections were selected or if they're appropriate

        2. CFO ANALYSIS - Check ONLY if:
           - Calculations were performed (results exist)
           - Do NOT check if the calculations are correct or appropriate

        3. CHART DATA - Check ONLY if:
           - Chart data structures were generated
           - Do NOT check if chart types are appropriate

        Return your assessment in this EXACT FORMAT:
        {{
            "needs_refinement": true/false,
            "feedback": {{
                "query_analyzer": "Feedback ONLY about whether data was fetched",
                "cfo": "Feedback ONLY about whether calculations were performed",
                "chart_agent": "Feedback ONLY about whether chart data was generated"
            }}
        }}

        IMPORTANT: For each agent that doesn't need refinement, include a brief "No issues found" message.
        """,
        expected_output="Quality assessment focused only on whether data was fetched, calculations were performed, and chart data was generated",
        agent=quality_analysis
    )

    return [query_task, cfo_task, chart_task, quality_task]

# Function to create multiple charts from JSON array
def create_charts_from_json(charts_data):
    try:
        # Parse the JSON if it's a string
        if isinstance(charts_data, str):
            # Find JSON array in the text
            json_match = re.search(r'\[\s*{.*}\s*\]', charts_data, re.DOTALL)
            if json_match:
                charts_array = json.loads(json_match.group())
            else:
                # Try to find a single JSON object
                json_match = re.search(r'{.*}', charts_data, re.DOTALL)
                if json_match:
                    charts_array = [json.loads(json_match.group())]
                else:
                    print("Error: No valid JSON found in chart data.")
                    return None
        else:
            charts_array = charts_data

        # Ensure we have a list of charts
        if not isinstance(charts_array, list):
            charts_array = [charts_array]

        # Calculate grid dimensions
        num_charts = len(charts_array)
        if num_charts == 0:
            print("Error: No charts to display.")
            return None

        # Create a figure with a grid layout
        # Use 2 columns, calculate needed rows
        cols = min(2, num_charts)
        rows = (num_charts + cols - 1) // cols  # Ceiling division

        fig = plt.figure(figsize=(16, 6 * rows))
        gs = GridSpec(rows, cols, figure=fig, wspace=0.3, hspace=0.4)

        # Track created axes to return
        all_axes = []

        # Create each chart
        for i, chart_dict in enumerate(charts_array):
            row = i // cols
            col = i % cols
            ax = fig.add_subplot(gs[row, col])
            all_axes.append(ax)

            chart_type = chart_dict.get('chart_type', 'line')
            chart_title = chart_dict.get('chart_title', f'Chart {i+1}')
            x_axis_label = chart_dict.get('x_axis_label', '')
            y_axis_label = chart_dict.get('y_axis_label', '')
            data = chart_dict.get('data', [])
            annotations = chart_dict.get('annotations', [])

            if not isinstance(data, list) or len(data) == 0:
                ax.text(0.5, 0.5, "Invalid or empty data", ha='center', va='center')
                continue

            if not all(isinstance(item, dict) for item in data):
                ax.text(0.5, 0.5, "Data items must be dictionaries", ha='center', va='center')
                continue

            # Identify x and y fields
            first_item = data[0]
            x_keys = [k for k in first_item.keys() if k.lower() in ['x', 'name', 'category', 'label', 'year']]
            y_keys = [k for k in first_item.keys() if k.lower() in ['y', 'value', 'amount']]

            if not x_keys or not y_keys:
                # Try alternative key detection
                x_field = list(first_item.keys())[0]
                y_field = list(first_item.keys())[1] if len(first_item.keys()) > 1 else None

                if not y_field:
                    ax.text(0.5, 0.5, "Cannot identify x and y fields", ha='center', va='center')
                    continue
            else:
                x_field = x_keys[0]
                y_field = y_keys[0]

            # Extract data
            x_values = [item.get(x_field) for item in data]
            y_values = [item.get(y_field) for item in data]

            # Create the appropriate chart type
            if chart_type.lower() == 'line':
                ax.plot(x_values, y_values, marker='o', linestyle='-')
                ax.grid(True, linestyle='--', alpha=0.7)

            elif chart_type.lower() == 'bar':
                ax.bar(x_values, y_values)
                ax.grid(True, linestyle='--', alpha=0.7, axis='y')

            elif chart_type.lower() == 'pie':
                wedges, texts, autotexts = ax.pie(
                    y_values,
                    labels=x_values if len(x_values) <= 5 else None,
                    autopct='%1.1f%%',
                    startangle=90
                )
                # If we have many slices, add a legend instead of labels
                if len(x_values) > 5:
                    ax.legend(wedges, x_values, loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))

            elif chart_type.lower() == 'stacked_bar':
                # For stacked bar charts, data structure is different
                # We expect multiple series with the same x values
                series_keys = set()
                x_categories = set()

                # Collect all series keys and x categories
                for item in data:
                    for key, value in item.items():
                        if key != x_field:
                            series_keys.add(key)
                    x_categories.add(item[x_field])

                # Convert to lists and sort
                x_categories = sorted(list(x_categories))
                series_keys = sorted(list(series_keys))

                # Create a matrix of values
                series_data = {series: [0] * len(x_categories) for series in series_keys}

                # Fill in the data
                for item in data:
                    x_idx = x_categories.index(item[x_field])
                    for series in series_keys:
                        if series in item:
                            series_data[series][x_idx] = item[series]

                # Plot the stacked bar
                bottom = np.zeros(len(x_categories))
                for series in series_keys:
                    ax.bar(x_categories, series_data[series], bottom=bottom, label=series)
                    bottom += np.array(series_data[series])

                ax.legend()

            else:
                # Fallback to line chart
                ax.plot(x_values, y_values, marker='o', linestyle='-')
                ax.grid(True, linestyle='--', alpha=0.7)

            # Add title and labels
            ax.set_title(chart_title)
            if chart_type.lower() != 'pie':
                ax.set_xlabel(x_axis_label)
                ax.set_ylabel(y_axis_label)

                # Add annotations if present
                if annotations:
                    for idx, annotation in enumerate(annotations):
                        if idx < len(x_values) and idx < len(y_values):
                            ax.annotate(
                                annotation,
                                (x_values[idx], y_values[idx]),
                                textcoords="offset points",
                                xytext=(0, 10),
                                ha='center'
                            )

        plt.tight_layout()
        return fig, all_axes

    except Exception as e:
        print(f"Error creating charts: {e}")
        import traceback
        traceback.print_exc()
        return None, []

# Main execution loop with refinement
try:
    while count < max_refinement_attempts:
        count += 1
        print(f"\n--- Attempt #{count} ---")

        # Create agents with refinement feedback if this is not the first attempt
        if count > 1:
            print(f"Refining analysis with feedback: {refinement_feedback}")
            query_analyzer, cfo, chart_agent, quality_analysis = create_agents(refinement_feedback)
        else:
            query_analyzer, cfo, chart_agent, quality_analysis = create_agents()

        # Create tasks
        tasks = create_tasks(query_analyzer, cfo, chart_agent, quality_analysis, query)

        # Create crew
        crew = Crew(
            agents=[query_analyzer, cfo, chart_agent, quality_analysis],
            tasks=tasks,
            verbose=False,
            memory=True
        )

        # Execute SQL query task
        result = query_analyzer.execute_task(tasks[0])
        sql_query = str(result).replace('```sql\n', '').replace('```', '').strip()
        print(f"SQL Query:\n{sql_query}")

        # Execute SQL and fetch data
        cursor.execute(sql_query)
        fetched_data = cursor.fetchall()

        col_names = [desc[0] for desc in cursor.description]

        formatted_data = []
        for row in fetched_data:
            formatted_row = {col_names[i]: row[i] for i in range(len(col_names))}
            formatted_data.append(formatted_row)

        if not fetched_data:
            print("No data found. Consider modifying your query or checking your data source.")
            break

        print(f"Data fetched successfully: {len(fetched_data)} rows.")

        # Execute CFO task with updated SQL query
        tasks[1].description += f"\n\nSQL Query used: {sql_query}"
        cfo_result = cfo.execute_task(tasks[1])
        print("\nAnalysis:")
        print(cfo_result)

        # Execute Chart task
        tasks[2].description += f"\n\nCFO Analysis: {cfo_result[:1000]}..." if len(cfo_result) > 1000 else f"\n\nCFO Analysis: {cfo_result}"
        chart_result = chart_agent.execute_task(tasks[2])
        print("\nChart Specifications:")

        # Parse and convert chart result to JSON
        try:
            # Try to extract JSON from the result if it's embedded in text
            json_match = re.search(r'\[\s*{.*}\s*\]', chart_result, re.DOTALL)
            if json_match:
                chart_json = json.loads(json_match.group())
            else:
                chart_json = json.loads(chart_result)

            # Create the charts (ensure this function doesn't call plt.show() inside it)
            fig, axes = create_charts_from_json(chart_json)
            if fig:
                # Only display once, remove redundant calls to display or plt.show()
                plt.show()

                # Save the figure as an image file
                fig.savefig('financial_analysis_charts.png', dpi=300, bbox_inches='tight')
                print("Charts saved as 'financial_analysis_charts.png'")
            else:
                print("Failed to create charts. Check the chart data for errors.")

        except Exception as e:
            print(f"Error parsing chart data: {e}")
            import traceback
            traceback.print_exc()


        # Execute Quality task and check if refinement is needed
        tasks[3].description += (
            f"\n\nSQL Query: {sql_query}\n\n"
            f"CFO Analysis: {cfo_result[:500]}...\n\n"
            f"Chart Specifications: {chart_result[:500]}..."
        )
        quality_result = quality_analysis.execute_task(tasks[3])
        print("\nQuality Assessment:")
        print(quality_result)

        # Parse quality result to determine if refinement is needed
        try:
            quality_json = json.loads(re.search(r'\{.*\}', quality_result, re.DOTALL).group())
            needs_refinement = quality_json.get('needs_refinement', False)
            refinement_feedback = quality_json.get('feedback', {})

            if not needs_refinement:
                print("Analysis complete! No refinement needed.")
                break

            if count >= max_refinement_attempts:
                print(f"Reached maximum refinement attempts ({max_refinement_attempts}). Proceeding with current results.")
                break

            print(f"Refinement requested. Starting attempt #{count+1}...")

        except Exception as e:
            print(f"Error parsing quality result: {e}")
            break

except Exception as e:
    print(f"Global Error: {e}")

finally:
    conn.close()

